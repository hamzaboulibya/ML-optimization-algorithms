{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62vSBvIB6mFV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import math\n",
        "data_train=pd.read_csv(r\"/content/drive/MyDrive/trainMnist.csv\")\n",
        "data_test=pd.read_csv(r\"/content/drive/MyDrive/trainMnist.csv\")\n",
        "\n",
        "data_train=np.array(data_train)\n",
        "data_test=np.array(data_test)\n",
        "\n",
        "nb_exemple,nb_pixels=data_train.shape\n",
        "nb_exemple_test,nb_pixels_test=data_test.shape\n",
        "\n",
        "np.random.shuffle(data_train)\n",
        "np.random.shuffle(data_test)\n",
        "\n",
        "data_train=data_train.T\n",
        "Y_train=data_train[0]\n",
        "X_train=data_train[1:nb_pixels]\n",
        "X_train=X_train/255.\n",
        "\n",
        "data_test=data_test.T\n",
        "Y_test=data_test[0]\n",
        "X_test=data_test[1:nb_pixels_test]\n",
        "X_test=X_test/255.\n",
        "\n",
        "def init_parametrs():\n",
        "    W1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    W2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A\n",
        "\n",
        "def forward_prop(W1,b1,W2,b2,X):\n",
        "    Z1=W1.dot(X) + b1\n",
        "    A1=ReLU(Z1)\n",
        "    Z2=W2.dot(A1) + b2\n",
        "    A2=softmax(Z2)\n",
        "    return Z1,A1,Z2,A2\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "\n",
        "def ReLU_deriv(Z):\n",
        "    return Z > 0\n",
        "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
        "    print(\"bwckword prop \",Y)\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    #erruer\n",
        "    dZ2 = A2 - one_hot_Y\n",
        "    #calculer deriver d'erruer hidden layer 2\n",
        "    dW2 = 1 / 1000 * dZ2.dot(A1.T)\n",
        "    db2 = 1 / 1000 * np.sum(dZ2)\n",
        "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
        "    dW1 = 1 / 1000 * dZ1.dot(X.T)\n",
        "    db1 = 1 / 1000 * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "#methode gradient\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "#methode momentieum\n",
        "def update_parametrs(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha,beta,dV1,dV2,dVB1,dVB2):\n",
        "    dV1=beta*dV1+(1-beta)*dW1\n",
        "    W1 = W1 - alpha * dV1\n",
        "\n",
        "    dVB1=beta*dVB1+(1-beta)*db1\n",
        "    b1 = b1 - alpha * dVB1\n",
        "\n",
        "    dV2=beta*dV2+(1-beta)*dW2\n",
        "    W2 = W2 - alpha * dV2\n",
        "\n",
        "    dVB2 = beta * dVB2 + (1 - beta) * db2\n",
        "    b2 = b2 - alpha * dVB2\n",
        "    return W1, b1, W2, b2,dV1,dV2,dVB1,dVB2\n",
        "\n",
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    # print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def loss_function(Y_train,Y_pre):\n",
        "    one_hot_Y = one_hot(Y_train)\n",
        "    return 0.5 * np.mean((Y_pre - one_hot_Y) ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RekWyJvkDr_q",
        "outputId": "2534043a-2206-4c46-de1d-eb2843e1f682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6, 4, 7, ..., 1, 1, 5],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ADAM**"
      ],
      "metadata": {
        "id": "en6p5vAW7qhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c,mb1c,mb2c):\n",
        "    alpha = 0.001\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    eps = 1e-8\n",
        "\n",
        "    W1 -= alpha * m1c / (np.sqrt(v1c) + eps)\n",
        "    W2 -= alpha * m2c / (np.sqrt(v2c) + eps)\n",
        "    b1 -= alpha * mb1c / (np.sqrt(vb1c) + eps)\n",
        "    b2 -= alpha * mb2c / (np.sqrt(vb2c) + eps)\n",
        "\n",
        "    # W1 = W1 - alpha * m1c * 1 / np.sqrt(v1c + eps)\n",
        "    # W2 = W2 - alpha * m2c * 1 / np.sqrt(v2c + eps)\n",
        "    # b1 = b1 - alpha * mb1c * 1 / np.sqrt(vb1c + eps)\n",
        "    # b2 = b2 - alpha * mb2c * 1 / np.sqrt(vb2c + eps)\n",
        "    # vraiiiiiiiiiiiii\n",
        "    m1c = m1 / (1 - beta1)\n",
        "    m2c = m2 / (1 - beta1)\n",
        "    mb1c = mb1 / (1 - beta1)\n",
        "    mb2c = mb2 / (1 - beta1)\n",
        "    # vraiiiiiiiiiiiii\n",
        "    v1c = v1 / (1 - beta2)\n",
        "    v2c = v2 / (1 - beta2)\n",
        "    vb1c = vb1 / (1 - beta2)\n",
        "    vb2c = vb2 / (1 - beta2)\n",
        "    # vraiiiiiiii\n",
        "\n",
        "\n",
        "    # m1 = beta1 * m1 + (1 - beta1) * dW1\n",
        "    # m2 = beta1 * m2 + (1 - beta1) * dW2\n",
        "    # mb1 = beta1 * mb1 + (1 - beta1) * db1\n",
        "    # mb2 = beta1 * mb2 + (1 - beta1) * db2\n",
        "    #\n",
        "    # v1 = beta2 * v1 + (1 - beta2) * (dW1**2)\n",
        "    # v2 = beta2 * v2 + (1 - beta2) * (dW2**2)\n",
        "    # vb1 = beta2 * vb1 + (1 - beta2) * (db1**2)\n",
        "    # vb2 = beta2 * vb2 + (1 - beta2) * (db2**2)\n",
        "    m1 = beta1 * m1 + (1 - beta1) * dW1\n",
        "    mb1 = beta1 * mb1 + (1 - beta1) * db1\n",
        "    m2 = beta1 * m2 + (1 - beta1) * dW2\n",
        "    mb2 = beta1* mb2 + (1 - beta1) * db2\n",
        "    # vraiiiiiiii\n",
        "    v1 = beta2 * v1 + (1 - beta2) * (dW1**2)\n",
        "    vb1 = beta2 * vb1 + (1 - beta2) *( db1**2)\n",
        "    v2 = beta2 * v2 + (1 - beta2) * (dW2**2)\n",
        "    vb2 = beta2* vb2 + (1 - beta2) * (db2**2)\n",
        "\n",
        "    return W1, b1, W2, b2, dW1, db1, dW2, db2, v1, v2, vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c,mb1c,mb2c\n",
        "\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_parametrs()\n",
        "    v1 = np.zeros(W1.shape)\n",
        "    vb1 = np.zeros(b1.shape)\n",
        "    v2 = np.zeros(W2.shape)\n",
        "    vb2 = np.zeros(b2.shape)\n",
        "\n",
        "    v1c = np.zeros(W1.shape)\n",
        "    vb1c = np.zeros(b1.shape)\n",
        "    v2c = np.zeros(W2.shape)\n",
        "    vb2c = np.zeros(b2.shape)\n",
        "\n",
        "    m1c = np.zeros(W1.shape)\n",
        "    mb1c = np.zeros(b1.shape)\n",
        "    m2c = np.zeros(W2.shape)\n",
        "    mb2c = np.zeros(b2.shape)\n",
        "\n",
        "    m1 = np.zeros(W1.shape)\n",
        "    mb1 = np.zeros(b1.shape)\n",
        "    m2 = np.zeros(W2.shape)\n",
        "    mb2 = np.zeros(b2.shape)\n",
        "\n",
        "\n",
        "    beta=0.9\n",
        "    W1, b1, W2, b2 = init_parametrs()\n",
        "    dV1= np.zeros(W1.shape)\n",
        "    dVB1=np.zeros(b1.shape)\n",
        "    dV2=np.zeros(W2.shape)\n",
        "    dVB2=np.zeros(b2.shape)\n",
        "    batch_Y=Y[0:1000]\n",
        "    for i in range(iterations):\n",
        "       # np.random.shuffle(X)\n",
        "       # np.random.shuffle(Y)\n",
        "        for p in range(0,nb_exemple,1000):\n",
        "            batch_X=X[:,p:p+1000]\n",
        "            batch_Y=Y[p:p+1000]\n",
        "            Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "            dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "            W1, b1, W2, b2, dW1, db1, dW2, db2, v1, v2, vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c, mb1c,mb2c = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2,vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c,mb1c,mb2c)\n",
        "            if i % 10 == 0:\n",
        "\n",
        "              print(\"Iteration: \", i)\n",
        "              predictions = get_predictions(A2)\n",
        "              print(get_accuracy(predictions, Y))\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10,2)"
      ],
      "metadata": {
        "id": "ewhYogdb7sym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "735b0630-c231-40ee-96e7-db9ca05b6b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.05383333333333333\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.05383333333333333\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.05383333333333333\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.05564285714285714\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.05904761904761905\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.063\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.06728571428571428\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.07273809523809524\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.07671428571428572\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.08102380952380953\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.0855\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.08952380952380952\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.09411904761904762\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.09802380952380953\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.10102380952380953\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.10404761904761904\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.10819047619047618\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.11192857142857143\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.11614285714285714\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.12097619047619047\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.12466666666666666\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.12921428571428573\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.13430952380952382\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.13904761904761906\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.14295238095238094\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.14626190476190476\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.1503095238095238\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.15416666666666667\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.15864285714285714\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.1631190476190476\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.1670952380952381\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.1705952380952381\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.17461904761904762\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.1785\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.18233333333333332\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.187\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.19026190476190477\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.19466666666666665\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.1995\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.20423809523809525\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.2087857142857143\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "Iteration:  0\n",
            "0.21404761904761904\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n",
            "bwckword prop  [9 5 2 ... 9 1 8]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b7095c7fc71c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ada grad**"
      ],
      "metadata": {
        "id": "wwMGcN5mA-VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1, vb2):\n",
        "    eps=0.00000001\n",
        "\n",
        "    v1=v1+dW1**2\n",
        "    v2=v2+dW2**2\n",
        "    vb1=vb1+db1**2\n",
        "    vb2=vb2+db2**2\n",
        "\n",
        "    W1 = W1 - alpha * dW1 *1/ np.sqrt(v1 + eps)\n",
        "    W2 = W2 - alpha * dW2 *1/ np.sqrt(v2 + eps)\n",
        "    b1 = b1 - alpha * db1 *1/ np.sqrt(vb1 + eps)\n",
        "    b2 = b2 - alpha * db2 *1/np.sqrt(vb2 + eps)\n",
        "\n",
        "    # beta = 0.9\n",
        "    # W1 = W1 - alpha * v1\n",
        "    # b1 = b1 - alpha * vb1\n",
        "    # W2 = W2 - alpha * v2\n",
        "    # b2 = b2 - alpha * vb2\n",
        "    # v1 = beta * v1 + (1 - beta) * dW1\n",
        "    # vb1 = beta * vb1 + (1 - beta) * db1\n",
        "    # v2 = beta * v2 + (1 - beta) * dW2\n",
        "    # vb2 = beta * vb2 + (1 - beta) * db2\n",
        "\n",
        "    return W1, b1, W2, b2, v1, v2, vb1, vb2\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    beta=0.9\n",
        "    W1, b1, W2, b2 = init_parametrs()\n",
        "    dV1= np.zeros(W1.shape)\n",
        "    dVB1=np.zeros(b1.shape)\n",
        "    dV2=np.zeros(W2.shape)\n",
        "    dVB2=np.zeros(b2.shape)\n",
        "    batch_Y=Y[0:1000]\n",
        "    w11 = np.zeros(W1.shape)\n",
        "    b11 = np.zeros(b1.shape)\n",
        "    w22 = np.zeros(W2.shape)\n",
        "    b22 = np.zeros(b2.shape)\n",
        "    for i in range(iterations):\n",
        "       # np.random.shuffle(X)\n",
        "       # np.random.shuffle(Y)\n",
        "        for p in range(0,nb_exemple,1000):\n",
        "            batch_X=X[:,p:p+1000]\n",
        "            batch_Y=Y[p:p+1000]\n",
        "            Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "            dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "            W1, b1, W2, b2, w11, w22, b11, b22 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, w11, w22, b11,b22)\n",
        "            if i % 10 == 0:\n",
        "                print(\"Iteration: \", i)\n",
        "                predictions = get_predictions(A2)\n",
        "                print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10,10)"
      ],
      "metadata": {
        "id": "TXu8aboLBHtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660e9c40-a261-40c8-a22c-2a58810e28ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "0.05604761904761905\n",
            "Iteration:  0\n",
            "0.14642857142857144\n",
            "Iteration:  0\n",
            "0.1789047619047619\n",
            "Iteration:  0\n",
            "0.25997619047619047\n",
            "Iteration:  0\n",
            "0.19138095238095237\n",
            "Iteration:  0\n",
            "0.2235\n",
            "Iteration:  0\n",
            "0.2917619047619048\n",
            "Iteration:  0\n",
            "0.3028571428571429\n",
            "Iteration:  0\n",
            "0.3259047619047619\n",
            "Iteration:  0\n",
            "0.3478809523809524\n",
            "Iteration:  0\n",
            "0.3645\n",
            "Iteration:  0\n",
            "0.37242857142857144\n",
            "Iteration:  0\n",
            "0.37907142857142856\n",
            "Iteration:  0\n",
            "0.38621428571428573\n",
            "Iteration:  0\n",
            "0.3916428571428571\n",
            "Iteration:  0\n",
            "0.3987142857142857\n",
            "Iteration:  0\n",
            "0.4037142857142857\n",
            "Iteration:  0\n",
            "0.41383333333333333\n",
            "Iteration:  0\n",
            "0.42192857142857143\n",
            "Iteration:  0\n",
            "0.4205238095238095\n",
            "Iteration:  0\n",
            "0.4111904761904762\n",
            "Iteration:  0\n",
            "0.42545238095238097\n",
            "Iteration:  0\n",
            "0.4519285714285714\n",
            "Iteration:  0\n",
            "0.45054761904761903\n",
            "Iteration:  0\n",
            "0.46676190476190477\n",
            "Iteration:  0\n",
            "0.4575714285714286\n",
            "Iteration:  0\n",
            "0.4707857142857143\n",
            "Iteration:  0\n",
            "0.4531428571428571\n",
            "Iteration:  0\n",
            "0.4635\n",
            "Iteration:  0\n",
            "0.453\n",
            "Iteration:  0\n",
            "0.47559523809523807\n",
            "Iteration:  0\n",
            "0.4724285714285714\n",
            "Iteration:  0\n",
            "0.5104285714285715\n",
            "Iteration:  0\n",
            "0.4906904761904762\n",
            "Iteration:  0\n",
            "0.523547619047619\n",
            "Iteration:  0\n",
            "0.5008809523809524\n",
            "Iteration:  0\n",
            "0.531\n",
            "Iteration:  0\n",
            "0.5038095238095238\n",
            "Iteration:  0\n",
            "0.539547619047619\n",
            "Iteration:  0\n",
            "0.5087619047619047\n",
            "Iteration:  0\n",
            "0.5552380952380952\n",
            "Iteration:  0\n",
            "0.5219761904761905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RMS **PROP**"
      ],
      "metadata": {
        "id": "pittANVSE8qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1, vb2):\n",
        "    eps=0.00000001\n",
        "    beta = 0.99\n",
        "    v1=beta*v1+(1-beta)*dW1**2\n",
        "    v2=beta*v2+(1-beta)*dW2**2\n",
        "    vb1=beta*vb1+(1-beta)*db1**2\n",
        "    vb2=beta*vb2+(1-beta)*db2**2\n",
        "    W1 = W1 - alpha * dW1 *1/ np.sqrt(v1 + eps)\n",
        "    W2 = W2 - alpha * dW2 *1/ np.sqrt(v2 + eps)\n",
        "    b1 = b1 - alpha * db1 *1/ np.sqrt(vb1 + eps)\n",
        "    b2 = b2 - alpha * db2 *1/np.sqrt(vb2 + eps)\n",
        "\n",
        "    return W1, b1, W2, b2, v1, v2, vb1, vb2\n",
        "\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    beta=0.9\n",
        "    W1, b1, W2, b2 = init_parametrs()\n",
        "    dV1= np.zeros(W1.shape)\n",
        "    dVB1=np.zeros(b1.shape)\n",
        "    dV2=np.zeros(W2.shape)\n",
        "    dVB2=np.zeros(b2.shape)\n",
        "    batch_Y=Y[0:1000]\n",
        "    w11 = np.zeros(W1.shape)\n",
        "    b11 = np.zeros(b1.shape)\n",
        "    w22 = np.zeros(W2.shape)\n",
        "    b22 = np.zeros(b2.shape)\n",
        "    for i in range(iterations):\n",
        "          # np.random.shuffle(X)\n",
        "          # np.random.shuffle(Y)\n",
        "            for p in range(0,nb_exemple,1000):\n",
        "                batch_X=X[:,p:p+1000]\n",
        "                batch_Y=Y[p:p+1000]\n",
        "                Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "                dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "                W1, b1, W2, b2, w11, w22, b11, b22 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, w11, w22, b11, b22)\n",
        "                if i % 10 == 0:\n",
        "                    print(\"Iteration: \", i)\n",
        "                    predictions = get_predictions(A2)\n",
        "                    print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
      ],
      "metadata": {
        "id": "f0tGYp4ME-3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adadelta **texte en gras**"
      ],
      "metadata": {
        "id": "vRkLkTEpGeKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1, vb2,D1,D2,Db1,Db2):\n",
        "    w1_old = W1.copy()\n",
        "    w2_old = W2.copy()\n",
        "    b1_old = b1.copy()\n",
        "    b2_old = b2.copy()\n",
        "\n",
        "    eps=0.00000001\n",
        "    beta = 0.9\n",
        "\n",
        "    v1 = beta * v1 + (1 - beta) * (dW1 ** 2)\n",
        "    v2 = beta * v2 + (1 - beta) * (dW2 ** 2)\n",
        "    vb1 = beta * vb1 + (1 - beta) * (db1 ** 2)\n",
        "    vb2 = beta * vb2 + (1 - beta) * (db2 ** 2)\n",
        "\n",
        "\n",
        "\n",
        "    W1 -= (np.sqrt(D1) + eps) * dW1 * 1 / np.sqrt(v1 + eps)\n",
        "    W2 -= (np.sqrt(D2) + eps) * dW2 * 1 / np.sqrt(v2 + eps)\n",
        "    b1 -= (np.sqrt(Db1) + eps) * db1 * 1 / np.sqrt(vb1 + eps)\n",
        "    b2 -= (np.sqrt(Db2) + eps) * db2 * 1 / np.sqrt(vb2 + eps)\n",
        "\n",
        "    D1 = beta * D1 + (1 - beta) * ((w1_old - W1) ** 2)\n",
        "    D2 = beta * D2 + (1 - beta) * ((w2_old - W2) ** 2)\n",
        "    Db1 = beta * Db1 + (1 - beta) * ((b1_old - b1) ** 2)\n",
        "    Db2 = beta * Db2 + (1 - beta) * ((b2_old - b2) ** 2)\n",
        "\n",
        "\n",
        "    return W1, b1, W2, b2, v1, v2, vb1, vb2 ,D1 ,D2 ,Db1 ,Db2\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_parametrs()\n",
        "    w11 = np.zeros(W1.shape)\n",
        "    b11 = np.zeros(b1.shape)\n",
        "    w22 = np.zeros(W2.shape)\n",
        "    b22 = np.zeros(b2.shape)\n",
        "    D1 = np.zeros(W1.shape)\n",
        "    Db1 = np.zeros(b1.shape)\n",
        "    D2 = np.zeros(W2.shape)\n",
        "    Db2 = np.zeros(b2.shape)\n",
        "    for i in range(iterations):\n",
        "          # np.random.shuffle(X)\n",
        "          # np.random.shuffle(Y)\n",
        "            for p in range(0,nb_exemple,1000):\n",
        "                batch_X=X[:,p:p+1000]\n",
        "                batch_Y=Y[p:p+1000]\n",
        "                Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "                dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "                W1, b1, W2, b2, w11, w22, b11, b22,D1,D2,Db1,Db2= update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, w11, w22, b11,b22,D1,D2,Db1,Db2)\n",
        "                if i % 10 == 0:\n",
        "                    print(\"Iteration: \", i)\n",
        "                    predictions = get_predictions(A2)\n",
        "                    print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 100)"
      ],
      "metadata": {
        "id": "PQ2KyYIdGhXW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}